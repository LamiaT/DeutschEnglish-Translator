{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vbaw5989ntAx"
   },
   "outputs": [],
   "source": [
    "# Neural Machine Translation Model\n",
    "\n",
    "# keywords = Seq2Seq model with Attention, Bahdanau Attention, \n",
    "# GRU architecture, Seq to Seq RNN, \n",
    "# Sequence-to-Sequence GRU RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F-LCFWFNntA2"
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "chxrDRa6ntA7"
   },
   "outputs": [],
   "source": [
    "# Prepping the dataset\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vVDAOS4OsC6V"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0quAaozdsC7i"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, DEUTSCH]\n",
    "\n",
    "def create_dataset(path, num_examples):\n",
    "    \n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    \n",
    "    return zip(*word_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "otPftMw2oxNm"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    \n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    \n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post')\n",
    "    \n",
    "    return tensor, lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w1kkim_DsDBt"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    \n",
    "    # creating cleaned input, output pairs\n",
    "    \n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    \n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2tK79NMesmHR"
   },
   "outputs": [],
   "source": [
    "path_to_file = '/content/deu.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0sKsUtA3ntA_"
   },
   "outputs": [],
   "source": [
    "# Using first 95000 examples from dataset\n",
    "\n",
    "num_examples = 95000\n",
    "\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDuj2ivuntBB",
    "outputId": "b9e16c9f-34f6-4f78-a63c-cd9c8a62db7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76000 76000 19000 19000\n"
     ]
    }
   ],
   "source": [
    "# Creating training, validation sets with 80-20 split ratio\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, \n",
    "                                                                                                target_tensor, \n",
    "                                                                                                test_size = 0.2)\n",
    "\n",
    "# Printing lengths\n",
    "\n",
    "print(len(input_tensor_train), \n",
    "      len(target_tensor_train), \n",
    "      len(input_tensor_val), \n",
    "      len(target_tensor_val)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UFWdMQn_ntBC"
   },
   "outputs": [],
   "source": [
    "# Function to display how data is encoded\n",
    "\n",
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88IikDGKntBE",
    "outputId": "201d064c-94b3-421f-d462-146b114acfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> die\n",
      "2223 ----> arbeiter\n",
      "14898 ----> grundeten\n",
      "29 ----> eine\n",
      "14899 ----> gewerkschaft\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "11 ----> the\n",
      "2585 ----> workers\n",
      "4297 ----> formed\n",
      "10 ----> a\n",
      "8510 ----> union\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "\n",
    "print ()\n",
    "\n",
    "print (\"Target Language; index to word mapping\")\n",
    "\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AASqkIn5ntBF"
   },
   "outputs": [],
   "source": [
    "# Creating Tensorflow dataset object; \n",
    "# to easily access it while training\n",
    "\n",
    "\n",
    "# Buffer Size while shuffling data\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "\n",
    "# Size of Embedding Layer\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of hidden units in GRU\n",
    "\n",
    "units = 1024\n",
    "\n",
    "# Size of Vocabulary at Encoder (i.e., Spanish)\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "\n",
    "# Size of Vocabulary at Decoder (i.e., English)\n",
    "\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "# Creating a Tensorflow Dataset Object\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, \n",
    "                                              target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, \n",
    "                        drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5ysaNR-ntBG",
    "outputId": "ef77d254-23c0-4c4e-f66c-a9edb5824fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n",
      "\n",
      "(64, 14)\n"
     ]
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "\n",
    "print(example_input_batch.shape)\n",
    "print()\n",
    "print(example_target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ewZZVjLNntBH"
   },
   "outputs": [],
   "source": [
    "# Creating the Model, using Sequence-to-Sequence GRU RNN architecture\n",
    "\n",
    "# Encoder - Decoder model with attention extension\n",
    "\n",
    "# Creating Encoder\n",
    "# Creating a Custom Layer\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_sz):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        '''\n",
    "        vocab_size : Size of the Vocabulary\n",
    "        embedding_dim : Size of the Embedding layer\n",
    "        enc_units : No. of Hidden Units in the GRU\n",
    "        batch_sz : Batch Size\n",
    "        '''\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.batch_sz = batch_sz\n",
    "        \n",
    "        #Embedding Layer\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        \n",
    "        #GRU\n",
    "        \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences = True,\n",
    "                                   return_state = True,\n",
    "                                   recurrent_initializer = 'glorot_uniform')\n",
    "    \n",
    "    # Function to create model with the layers \n",
    "    \n",
    "    def call(self,inp,hidden):\n",
    "        \n",
    "        '''\n",
    "        inp: input to the model.i.e., vectorized form of the spanish sentence\n",
    "        hidden: intial hidden_state of the gru.\n",
    "        '''\n",
    "        \n",
    "        x = self.embedding(inp)\n",
    "        \n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    # Function to initialize the initial hidden state of GRU\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        \n",
    "        return tf.zeros([self.batch_sz, \n",
    "                         self.enc_units]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "k0zjaFPpntBI"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, \n",
    "                  embedding_dim, \n",
    "                  units, \n",
    "                  BATCH_SIZE\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQLao4PJntBJ",
    "outputId": "468892c4-2fbf-470a-e694-6e5b67bf40d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "\n",
    "sample_output, sample_hidden = encoder(example_input_batch, \n",
    "                                       sample_hidden)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "C2gTz7ZfntBJ"
   },
   "outputs": [],
   "source": [
    "# Creating Bahdanau Attention\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,units):\n",
    "        \n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        \n",
    "        '''\n",
    "        units: Number of hidden Units , represented as \"h_u\" in the article\n",
    "        '''\n",
    "        \n",
    "        self.units = units\n",
    "        \n",
    "        self.W1 = tf.keras.layers.Dense(self.units)\n",
    "        \n",
    "        self.W2 = tf.keras.layers.Dense(self.units)\n",
    "        \n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "    #Function that will create the model with the layers \n",
    "    \n",
    "    def call(self,query, values):\n",
    "        \n",
    "        '''\n",
    "        query : The hidden state of the GRUs \"refer to B\"\n",
    "        values: The output of the GRUs \"refer to A\"\n",
    "        '''\n",
    "        \n",
    "        #To ccnvert the query from 2-D to 3-D\n",
    "        \n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        #Implementation of STEP-1\n",
    "        \n",
    "        '''Both query and Values are passed into a dense layer with units \"h_u\"\n",
    "        and,added together,after that a tanh activation is applied and finally\n",
    "        the result is passed into a dense layer with one neuron. ''' \n",
    "        \n",
    "        score = self.V(tf.keras.activations.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values))\n",
    "                      )\n",
    "        \n",
    "        # Implementaion of STEP-2\n",
    "        \n",
    "        attention_weights = tf.keras.activations.softmax(score, 1)\n",
    "        \n",
    "        #Implementation of STEP-3 \n",
    "        \n",
    "        context_vector =  attention_weights * values\n",
    "        \n",
    "        context_vector = tf.reduce_sum(context_vector, 1)\n",
    "        \n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lJAD_s7ntBK",
    "outputId": "3d7aab78-b04d-4ffa-927d-cd44a488ece4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) : (64, 1024)\n",
      "\n",
      "Attention weights shape: (batch_size, sequence_length, 1) : (64, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, \n",
    "                                                      sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) : {}\".format(attention_result.shape))\n",
    "print()\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) : {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "y9luqkWentBL"
   },
   "outputs": [],
   "source": [
    "# Creating Decoder\n",
    "\n",
    "# Creating a Custom Layer\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        \n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        '''\n",
    "        vocab_size : Size of vocabulary for the resulting sentence (i.e.,English)\n",
    "        embedding_dim : Size of the Embedding layer\n",
    "        enc_units : No. of Hidden Units in the GRU\n",
    "        batch_sz : Batch Size\n",
    "        '''\n",
    "        \n",
    "        self.dec_units = dec_units\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        \n",
    "        # Embedding layer\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
    "                                                   embedding_dim)\n",
    "        \n",
    "        # GRU\n",
    "        \n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences = True,\n",
    "                                       return_state = True,\n",
    "                                       recurrent_initializer = 'glorot_uniform')\n",
    "        \n",
    "        # Dense Layer\n",
    "        \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # An Instance of attention layer \n",
    "        \n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    \n",
    "    \n",
    "    #Function that will create the model with the layers \n",
    "    \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        '''\n",
    "        x :Input to the decoder\n",
    "        hidden: Hidden state of the GRU\n",
    "        enc_output: Output from the encoder layer (not attention layer)\n",
    "        '''\n",
    "        \n",
    "        '''I combined the attention layer with the decoder layer.So that the attention \n",
    "        is calculated at the decoder.'''\n",
    "        \n",
    "        #Calculate attention vector\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(hidden, \n",
    "                                                           enc_output)\n",
    "        \n",
    "        #Embedding Layer\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #Concating the attention vector with x\n",
    "        \n",
    "        x = tf.concat( [ tf.expand_dims(context_vector, 1), x ], \n",
    "                      axis = -1 )\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        #just Reshaaping the output i.e., (Batch_Size,Vocab_Dims)\n",
    "        \n",
    "        output = tf.reshape(output,(-1, output.shape[2]))\n",
    "        \n",
    "        #Passing it through a Dense layer\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExyUmy92ntBM",
    "outputId": "5f586e8f-8367-4d6c-b85c-fba79a45c9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) = (64, 9819)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, \n",
    "                  embedding_dim, \n",
    "                  units, \n",
    "                  BATCH_SIZE\n",
    "                 )\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform( (BATCH_SIZE, 1) ),\n",
    "                                      sample_hidden, \n",
    "                                      sample_output\n",
    "                                     )\n",
    "\n",
    "print('Decoder output shape: (batch_size, vocab size) = {}'.format(sample_decoder_output.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Yxn6qDc5ntBN"
   },
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "\n",
    "# using Adam Optimizer, and Sparse Categorical Cross Entropy loss\n",
    "\n",
    "# Creating Optimizer Object\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Creating Loss Object\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, \n",
    "                                                            reduction = 'none'\n",
    "                                                           )\n",
    "\n",
    "''' We will be taking bulks of data from the dataset while training\n",
    "This function just uses the Loss Object to deal with a bulk of data, \n",
    "and calculate loss for the whole bulk'''\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \n",
    "    mask = tf.math.logical_not( tf.math.equal(real, 0) )\n",
    "    \n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    \n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EeCbuTlfntBO"
   },
   "outputs": [],
   "source": [
    "# Storing Model Progress while Training\n",
    "\n",
    "# Checkpoint Storing Path \n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "# Index of Checkpoint\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "# Checkpoint Object that will store the state of each layer\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer = optimizer,\n",
    "                                 encoder = encoder,\n",
    "                                 decoder = decoder\n",
    "                                )\n",
    "\n",
    "# we combined the Attention layer with the decoder layer so we don't\n",
    "# have to save it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "W9SnVtpontBO"
   },
   "outputs": [],
   "source": [
    "def train_step(inp,targ,enc_hidden):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # Step-4\n",
    "        \n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        # Step-7\n",
    "        \n",
    "        dec_input = tf.expand_dims([ targ_lang.word_index['<start>'] ] * BATCH_SIZE, \n",
    "                                   1\n",
    "                                  )\n",
    "        \n",
    "        # We have to concatenate the decoder input with the attention vector\n",
    "        # So we have to convert it into 2-D by expanding Dims.\n",
    "        \n",
    "        for t in range(1, targ.shape[1]):\n",
    "            \n",
    "            predictions, dec_hidden,_ = decoder(dec_input, \n",
    "                                                dec_hidden, \n",
    "                                                enc_output\n",
    "                                               )\n",
    "            \n",
    "            # Increment the loss,targ[:,t] means we are calculating loss for the \n",
    "            # t'th word in all batches at the same time.(BULK!)\n",
    "            \n",
    "            loss += loss_function(targ[:,t], predictions)\n",
    "            \n",
    "            # We have to concatenate the decoder input with the attention vector\n",
    "            # So we have to convert it into 2-D by expanding Dims.\n",
    "            \n",
    "            dec_input = tf.expand_dims(targ[:,t], 1)\n",
    "            \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    \n",
    "    # Get all the trainable variables\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    # Calculate Derivative\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    # Apply the gradients\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93MSS3ylntBP",
    "outputId": "d17b24a8-e96d-4d6e-a009-e3ac10329773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7294\n",
      "Epoch 1 Batch 100 Loss 2.1914\n",
      "Epoch 1 Batch 200 Loss 2.0314\n",
      "Epoch 1 Batch 300 Loss 1.6942\n",
      "Epoch 1 Batch 400 Loss 1.8506\n",
      "Epoch 1 Batch 500 Loss 1.6889\n",
      "Epoch 1 Batch 600 Loss 1.4352\n",
      "Epoch 1 Batch 700 Loss 1.3825\n",
      "Epoch 1 Batch 800 Loss 1.4946\n",
      "Epoch 1 Batch 900 Loss 1.2470\n",
      "Epoch 1 Batch 1000 Loss 1.1410\n",
      "Epoch 1 Batch 1100 Loss 1.1949\n",
      "Epoch 1 Loss 1.6227\n",
      "\n",
      "Time taken for 1 epoch 503.5951602458954 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.9797\n",
      "Epoch 2 Batch 100 Loss 1.0613\n",
      "Epoch 2 Batch 200 Loss 1.0554\n",
      "Epoch 2 Batch 300 Loss 1.0541\n",
      "Epoch 2 Batch 400 Loss 0.8628\n",
      "Epoch 2 Batch 500 Loss 0.7814\n",
      "Epoch 2 Batch 600 Loss 0.9397\n",
      "Epoch 2 Batch 700 Loss 0.8902\n",
      "Epoch 2 Batch 800 Loss 0.8064\n",
      "Epoch 2 Batch 900 Loss 0.8485\n",
      "Epoch 2 Batch 1000 Loss 0.8857\n",
      "Epoch 2 Batch 1100 Loss 0.7488\n",
      "Epoch 2 Loss 0.8739\n",
      "\n",
      "Time taken for 1 epoch 489.92234349250793 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5439\n",
      "Epoch 3 Batch 100 Loss 0.5394\n",
      "Epoch 3 Batch 200 Loss 0.5818\n",
      "Epoch 3 Batch 300 Loss 0.5305\n",
      "Epoch 3 Batch 400 Loss 0.4895\n",
      "Epoch 3 Batch 500 Loss 0.5053\n",
      "Epoch 3 Batch 600 Loss 0.6224\n",
      "Epoch 3 Batch 700 Loss 0.5271\n",
      "Epoch 3 Batch 800 Loss 0.5265\n",
      "Epoch 3 Batch 900 Loss 0.5134\n",
      "Epoch 3 Batch 1000 Loss 0.5319\n",
      "Epoch 3 Batch 1100 Loss 0.3994\n",
      "Epoch 3 Loss 0.5391\n",
      "\n",
      "Time taken for 1 epoch 492.9413402080536 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.3116\n",
      "Epoch 4 Batch 100 Loss 0.3374\n",
      "Epoch 4 Batch 200 Loss 0.3358\n",
      "Epoch 4 Batch 300 Loss 0.3634\n",
      "Epoch 4 Batch 400 Loss 0.3808\n",
      "Epoch 4 Batch 500 Loss 0.3490\n",
      "Epoch 4 Batch 600 Loss 0.3605\n",
      "Epoch 4 Batch 700 Loss 0.3212\n",
      "Epoch 4 Batch 800 Loss 0.3782\n",
      "Epoch 4 Batch 900 Loss 0.3850\n",
      "Epoch 4 Batch 1000 Loss 0.3566\n",
      "Epoch 4 Batch 1100 Loss 0.3411\n",
      "Epoch 4 Loss 0.3589\n",
      "\n",
      "Time taken for 1 epoch 491.5390508174896 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2321\n",
      "Epoch 5 Batch 100 Loss 0.2115\n",
      "Epoch 5 Batch 200 Loss 0.1996\n",
      "Epoch 5 Batch 300 Loss 0.2416\n",
      "Epoch 5 Batch 400 Loss 0.2725\n",
      "Epoch 5 Batch 500 Loss 0.2700\n",
      "Epoch 5 Batch 600 Loss 0.2550\n",
      "Epoch 5 Batch 700 Loss 0.2017\n",
      "Epoch 5 Batch 800 Loss 0.2791\n",
      "Epoch 5 Batch 900 Loss 0.2283\n",
      "Epoch 5 Batch 1000 Loss 0.2531\n",
      "Epoch 5 Batch 1100 Loss 0.2548\n",
      "Epoch 5 Loss 0.2510\n",
      "\n",
      "Time taken for 1 epoch 486.8164813518524 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2135\n",
      "Epoch 6 Batch 100 Loss 0.1659\n",
      "Epoch 6 Batch 200 Loss 0.1405\n",
      "Epoch 6 Batch 300 Loss 0.1709\n",
      "Epoch 6 Batch 400 Loss 0.1861\n",
      "Epoch 6 Batch 500 Loss 0.2444\n",
      "Epoch 6 Batch 600 Loss 0.2054\n",
      "Epoch 6 Batch 700 Loss 0.2087\n",
      "Epoch 6 Batch 800 Loss 0.2154\n",
      "Epoch 6 Batch 900 Loss 0.1605\n",
      "Epoch 6 Batch 1000 Loss 0.2402\n",
      "Epoch 6 Batch 1100 Loss 0.2100\n",
      "Epoch 6 Loss 0.1844\n",
      "\n",
      "Time taken for 1 epoch 494.96524572372437 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1169\n",
      "Epoch 7 Batch 100 Loss 0.1325\n",
      "Epoch 7 Batch 200 Loss 0.1125\n",
      "Epoch 7 Batch 300 Loss 0.1268\n",
      "Epoch 7 Batch 400 Loss 0.1609\n",
      "Epoch 7 Batch 500 Loss 0.1305\n",
      "Epoch 7 Batch 600 Loss 0.1598\n",
      "Epoch 7 Batch 700 Loss 0.1502\n",
      "Epoch 7 Batch 800 Loss 0.1566\n",
      "Epoch 7 Batch 900 Loss 0.1508\n",
      "Epoch 7 Batch 1000 Loss 0.1720\n",
      "Epoch 7 Batch 1100 Loss 0.1743\n",
      "Epoch 7 Loss 0.1435\n",
      "\n",
      "Time taken for 1 epoch 487.7742278575897 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0979\n",
      "Epoch 8 Batch 100 Loss 0.1184\n",
      "Epoch 8 Batch 200 Loss 0.1032\n",
      "Epoch 8 Batch 300 Loss 0.1047\n",
      "Epoch 8 Batch 400 Loss 0.1099\n",
      "Epoch 8 Batch 500 Loss 0.1153\n",
      "Epoch 8 Batch 600 Loss 0.0950\n",
      "Epoch 8 Batch 700 Loss 0.1647\n",
      "Epoch 8 Batch 800 Loss 0.1142\n",
      "Epoch 8 Batch 900 Loss 0.1447\n",
      "Epoch 8 Batch 1000 Loss 0.1386\n",
      "Epoch 8 Batch 1100 Loss 0.1115\n",
      "Epoch 8 Loss 0.1154\n",
      "\n",
      "Time taken for 1 epoch 483.24177408218384 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0724\n",
      "Epoch 9 Batch 100 Loss 0.0818\n",
      "Epoch 9 Batch 200 Loss 0.0842\n",
      "Epoch 9 Batch 300 Loss 0.0918\n",
      "Epoch 9 Batch 400 Loss 0.1078\n",
      "Epoch 9 Batch 500 Loss 0.0951\n",
      "Epoch 9 Batch 600 Loss 0.0773\n",
      "Epoch 9 Batch 700 Loss 0.0981\n",
      "Epoch 9 Batch 800 Loss 0.0754\n",
      "Epoch 9 Batch 900 Loss 0.1118\n",
      "Epoch 9 Batch 1000 Loss 0.1274\n",
      "Epoch 9 Batch 1100 Loss 0.1420\n",
      "Epoch 9 Loss 0.0983\n",
      "\n",
      "Time taken for 1 epoch 482.6613509654999 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0900\n",
      "Epoch 10 Batch 100 Loss 0.0663\n",
      "Epoch 10 Batch 200 Loss 0.0679\n",
      "Epoch 10 Batch 300 Loss 0.0752\n",
      "Epoch 10 Batch 400 Loss 0.0735\n",
      "Epoch 10 Batch 500 Loss 0.1053\n",
      "Epoch 10 Batch 600 Loss 0.0799\n",
      "Epoch 10 Batch 700 Loss 0.0892\n",
      "Epoch 10 Batch 800 Loss 0.0824\n",
      "Epoch 10 Batch 900 Loss 0.0647\n",
      "Epoch 10 Batch 1000 Loss 0.0840\n",
      "Epoch 10 Batch 1100 Loss 0.0841\n",
      "Epoch 10 Loss 0.0868\n",
      "\n",
      "Time taken for 1 epoch 480.50377678871155 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0531\n",
      "Epoch 11 Batch 100 Loss 0.0685\n",
      "Epoch 11 Batch 200 Loss 0.0630\n",
      "Epoch 11 Batch 300 Loss 0.0598\n",
      "Epoch 11 Batch 400 Loss 0.0577\n",
      "Epoch 11 Batch 500 Loss 0.0699\n",
      "Epoch 11 Batch 600 Loss 0.0745\n",
      "Epoch 11 Batch 700 Loss 0.1062\n",
      "Epoch 11 Batch 800 Loss 0.0598\n",
      "Epoch 11 Batch 900 Loss 0.0883\n",
      "Epoch 11 Batch 1000 Loss 0.0745\n",
      "Epoch 11 Batch 1100 Loss 0.0693\n",
      "Epoch 11 Loss 0.0780\n",
      "\n",
      "Time taken for 1 epoch 482.1167848110199 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0807\n",
      "Epoch 12 Batch 100 Loss 0.0501\n",
      "Epoch 12 Batch 200 Loss 0.0708\n",
      "Epoch 12 Batch 300 Loss 0.0687\n",
      "Epoch 12 Batch 400 Loss 0.0593\n",
      "Epoch 12 Batch 500 Loss 0.0618\n",
      "Epoch 12 Batch 600 Loss 0.0675\n",
      "Epoch 12 Batch 700 Loss 0.0680\n",
      "Epoch 12 Batch 800 Loss 0.0435\n",
      "Epoch 12 Batch 900 Loss 0.1026\n",
      "Epoch 12 Batch 1000 Loss 0.1058\n",
      "Epoch 12 Batch 1100 Loss 0.0940\n",
      "Epoch 12 Loss 0.0711\n",
      "\n",
      "Time taken for 1 epoch 486.3939051628113 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0704\n",
      "Epoch 13 Batch 100 Loss 0.0425\n",
      "Epoch 13 Batch 200 Loss 0.0296\n",
      "Epoch 13 Batch 300 Loss 0.0328\n",
      "Epoch 13 Batch 400 Loss 0.0578\n",
      "Epoch 13 Batch 500 Loss 0.0522\n",
      "Epoch 13 Batch 600 Loss 0.0602\n",
      "Epoch 13 Batch 700 Loss 0.0756\n",
      "Epoch 13 Batch 800 Loss 0.0579\n",
      "Epoch 13 Batch 900 Loss 0.0686\n",
      "Epoch 13 Batch 1000 Loss 0.0901\n",
      "Epoch 13 Batch 1100 Loss 0.0720\n",
      "Epoch 13 Loss 0.0665\n",
      "\n",
      "Time taken for 1 epoch 484.6115913391113 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0538\n",
      "Epoch 14 Batch 100 Loss 0.0500\n",
      "Epoch 14 Batch 200 Loss 0.0505\n",
      "Epoch 14 Batch 300 Loss 0.0762\n",
      "Epoch 14 Batch 400 Loss 0.0752\n",
      "Epoch 14 Batch 500 Loss 0.0598\n",
      "Epoch 14 Batch 600 Loss 0.0275\n",
      "Epoch 14 Batch 700 Loss 0.0941\n",
      "Epoch 14 Batch 800 Loss 0.0548\n",
      "Epoch 14 Batch 900 Loss 0.0653\n",
      "Epoch 14 Batch 1000 Loss 0.0767\n",
      "Epoch 14 Batch 1100 Loss 0.0565\n",
      "Epoch 14 Loss 0.0645\n",
      "\n",
      "Time taken for 1 epoch 489.3003101348877 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0583\n",
      "Epoch 15 Batch 100 Loss 0.0295\n",
      "Epoch 15 Batch 200 Loss 0.0302\n",
      "Epoch 15 Batch 300 Loss 0.0490\n",
      "Epoch 15 Batch 400 Loss 0.0879\n",
      "Epoch 15 Batch 500 Loss 0.0527\n",
      "Epoch 15 Batch 600 Loss 0.0716\n",
      "Epoch 15 Batch 700 Loss 0.0585\n",
      "Epoch 15 Batch 800 Loss 0.0669\n",
      "Epoch 15 Batch 900 Loss 0.0762\n",
      "Epoch 15 Batch 1000 Loss 0.0612\n",
      "Epoch 15 Batch 1100 Loss 0.0663\n",
      "Epoch 15 Loss 0.0619\n",
      "\n",
      "Time taken for 1 epoch 489.49241948127747 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the number of epochs\n",
    "\n",
    "EPOCH = 15\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    #To calculate time taken for each epoch\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Initializing the hidden state of the Encoder model\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    \n",
    "    # Initializing total loss, which is zero initially\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    # Taking batches of data\n",
    "    \n",
    "    for (batch,(inp,targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        \n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        #Printing stats after 100 batches\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            \n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()\n",
    "                                                        ) )\n",
    "        \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "        \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "            \n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            \n",
    "    #Printing some stats.\n",
    "        \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "I10YB68QntBQ"
   },
   "outputs": [],
   "source": [
    "#Function that translates a given sentence\n",
    "def evaluate(sentence):\n",
    "    \n",
    "    #This is to store the attention vector for plotting.Ignore this\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    #Preprocessing the sentence.Steps 2,3 and 4\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    \n",
    "    #Step 4\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    #creating a string to store the translated sentence\n",
    "    result = ''\n",
    "\n",
    "    #Step 5\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    #Step 6\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    #Step 7\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on.Ignore it\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        #Step 8\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    #Return the Original Sentence,Translated Sentence and the history of attention weights\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDCUKtqLntBQ",
    "outputId": "491a05db-f2ff-4211-9b53-45fb9ef6d2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i won ! <end> \n"
     ]
    }
   ],
   "source": [
    "sentence = u'Ich hab gewonnen!'\n",
    "translation,_,_ = evaluate(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "uKQxs3CSntBQ"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "qI9QsWAsntBR"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Translation: {}'.format(result))\n",
    "    print()\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    \n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvjm2vjOntBR",
    "outputId": "e692e83f-d844-493e-f82e-15cf5a164ac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7c86287f10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "A6qcZB9lsKbS",
    "outputId": "557b6eba-4423-4b31-88c4-c04c3e36f1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ich hab gewonnen ! <end>\n",
      "Predicted translation: i won ! <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Ich hab gewonnen!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "dGgopMZesKgV",
    "outputId": "69e93be6-089b-47c1-8889-a97b47192e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hallo ! <end>\n",
      "Predicted translation: hello ! <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Hallo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "cIddcTHaa0VO",
    "outputId": "b0fc1715-06ce-4afe-f319-ce8270ffa957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> willkommen ! <end>\n",
      "Predicted translation: welcome . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Willkommen!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "vTe7N0kCD0f8",
    "outputId": "307b5e71-634c-4601-ba9a-06dd261890eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> lamia . <end>\n",
      "Predicted translation: lamia . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Lamia.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGOF3badEWqv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Final V P2 COMPLETE GER - ENG 50000 examples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
